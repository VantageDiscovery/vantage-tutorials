{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0007083c-a67a-4bc7-9fd4-c965acc2a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Parquet file\n",
    "df = pd.read_parquet('./vantage_furniture_tutorial.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079357e-a839-4383-93b0-c6704389d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "# Function to create MD5 hash of a string\n",
    "def create_md5_hash(string):\n",
    "    return hashlib.md5(string.encode()).hexdigest()\n",
    "\n",
    "# Function to transform URL slug into a title\n",
    "def url_to_title(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    title = parsed_url.path.split('/')[-1].replace('-', ' ')\n",
    "    title = unquote(title)\n",
    "    return title.title()\n",
    "\n",
    "# Function to bucket ratings\n",
    "def bucket_rating(rating):\n",
    "    if rating == 5.0:\n",
    "        return '5 stars'\n",
    "    elif rating >= 4.0:\n",
    "        return '4 stars and up'\n",
    "    elif rating >= 3.0:\n",
    "        return '3 stars and up'\n",
    "    elif rating >= 2.0:\n",
    "        return '2 stars and up'\n",
    "    else:\n",
    "        return 'Less than 2 stars'\n",
    "\n",
    "# Function to bucket number of ratings\n",
    "def bucket_numratings(numratings):\n",
    "    if numratings == 0:\n",
    "        return 'none'\n",
    "    elif numratings < 10:\n",
    "        return 'few'\n",
    "    elif numratings < 100:\n",
    "        return 'dozens'\n",
    "    elif numratings < 1000:\n",
    "        return 'hundreds'\n",
    "    else:\n",
    "        return '1000+'\n",
    "\n",
    "# prep\n",
    "df.rename(columns={'id':'noop_url'}, inplace=True)\n",
    "\n",
    "# 0. new id\n",
    "df['id'] = df['noop_url'].apply(create_md5_hash)\n",
    "\n",
    "# 1. Drop specified columns\n",
    "df.drop(['meta_category_l1', 'meta_category_l2', 'meta_category_l3'], axis=1, inplace=True)\n",
    "\n",
    "# 2. Rename 'meta_category_l4' to 'meta_category'\n",
    "df.rename(columns={'meta_category_l4': 'meta_category'}, inplace=True)\n",
    "\n",
    "# 2a. Rename 'meta_image' to 'noop_image_url'\n",
    "df.rename(columns={'meta_image': 'noop_image_url'}, inplace=True)\n",
    "\n",
    "# 3. Rename 'meta_rating' to 'noop_rating'\n",
    "df.rename(columns={'meta_rating': 'noop_rating'}, inplace=True)\n",
    "\n",
    "# 4. Create 'meta_rating_bucket' from 'noop_rating'\n",
    "df['meta_rating_bucket'] = df['noop_rating'].apply(bucket_rating)\n",
    "\n",
    "# 5. Rename 'meta_numratings' to 'noop_numratings'\n",
    "df.rename(columns={'meta_numratings': 'noop_numratings'}, inplace=True)\n",
    "\n",
    "# 6. Create 'meta_numratings_bucket' from 'noop_numratings'\n",
    "df['meta_numratings_bucket'] = df['noop_numratings'].apply(bucket_numratings)\n",
    "\n",
    "# 7. Creating a new column 'noop_description' with the first 255 characters of the 'description' column\n",
    "df['noop_description'] = df['text'].str.slice(0, 255)\n",
    "\n",
    "# 8. title from url\n",
    "df['noop_title'] = df['noop_url'].apply(url_to_title)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f0e72-9b69-40d6-a987-4d582a0e7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reordering the columns in the DataFrame before saving to a parquet file\n",
    "meta_columns = [col for col in df.columns if col.startswith('meta_')]\n",
    "noop_columns = [col for col in df.columns if col.startswith('noop_')]\n",
    "\n",
    "# Constructing the new column order\n",
    "new_column_order = ['id', 'text'] + meta_columns + noop_columns\n",
    "\n",
    "# Reordering the DataFrame\n",
    "df_reordered = df[new_column_order]\n",
    "\n",
    "# Saving the DataFrame to a parquet file\n",
    "output_file_path = './furniture.parquet'  # Specifying the file path\n",
    "df_reordered.to_parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7695d5-072d-448c-b33e-0088de10a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame here\n",
    "# df_reordered = pd.read_parquet('furniture.parquet')\n",
    "\n",
    "# Create the directory 'public' if it doesn't exist\n",
    "output_dir = './public'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the DataFrame and write each row to a separate JSON file\n",
    "for index, row in df_reordered.iterrows():\n",
    "    # Convert NaN values to None\n",
    "    row_cleaned = row.where(pd.notnull(row), None)\n",
    "    \n",
    "    # Constructing the file name\n",
    "    file_name = os.path.join(output_dir, f\"{row_cleaned['id']}.json\")\n",
    "    \n",
    "    # Convert the row to a dictionary and write to a JSON file\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(row_cleaned.to_dict(), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd626b1-00cc-4a01-9228-f56ed827fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjusting the function to create the JSON file in the accessible directory\n",
    "def create_json_file(df, column_name):\n",
    "    # Generate the nice, init upper cased without underscores version of the column name\n",
    "    nice_name = column_name.replace(\"meta_\", \"\").replace(\"_\", \" \").title()\n",
    "    slug = column_name.replace(\"meta_\", \"\")\n",
    "    \n",
    "    # Find distinct values in the column\n",
    "    distinct_values = df[column_name].dropna().unique()\n",
    "    \n",
    "    # Create JSON data\n",
    "    json_data = [\n",
    "        {\n",
    "            \"name\": value,\n",
    "            \"slug\": value,\n",
    "            \"categoryName\": nice_name,\n",
    "            \"categorySlug\": slug,\n",
    "            \"count\": df[df[column_name] == value].shape[0]\n",
    "        }\n",
    "        for value in distinct_values\n",
    "    ]\n",
    "    \n",
    "    # Write to file\n",
    "    file_path = \"public/\" + column_name + \".json\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# Creating JSON files for each column with 'meta_' prefix\n",
    "json_files = [create_json_file(df, column) for column in df.columns if column.startswith('meta_')]\n",
    "json_files_paths = {column: create_json_file(df, column) for column in df.columns if column.startswith('meta_')}\n",
    "json_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178adcb-b42f-4bb3-8c0c-ca243ecb627b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
